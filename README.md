# ORION â€“ Visual Intelligence ðŸš€

**Privacy-first, fully on-device real-time electronic component detection using YOLOv8 and TensorFlow Lite**

ORION â€“ Visual Intelligence is an end-to-end mobile computer vision system that performs real-time electronic component detection entirely **on-device**, without relying on cloud services or network connectivity.

This project showcases a complete **production-style ML + Android pipeline**, covering dataset creation, model training, evaluation, TensorFlow Lite optimization, and hardware-accelerated inference on real Android devices.

---

## ðŸ§  Overview

ORION detects common electronic components directly from a live camera feed:

* Resistors
* Capacitors
* Transistors
* ICs (Integrated Circuits)
* PCBs (Printed Circuit Boards)

All inference is executed locally on the device, ensuring **low latency, offline functionality, and user privacy**.

---

## ðŸ—ï¸ Project Structure

```
ORION-Visual-Intelligence/
â”œâ”€â”€ android/        # Android application (CameraX + TensorFlow Lite)
â”œâ”€â”€ orion-core/     # Model training, evaluation, and conversion pipeline
â”œâ”€â”€ README.md       # Project documentation
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Technology Stack

### Machine Learning & Computer Vision

* YOLOv8 (Ultralytics)
* PyTorch
* TensorFlow Lite (FP32 â†’ FP16 conversion)
* Google Colab

### Mobile & Edge Deployment

* Android (Kotlin)
* CameraX
* TensorFlow Lite Interpreter
* GPU Delegate (primary acceleration)
* NNAPI Delegate (fallback)

### Tooling & Utilities

* Roboflow (dataset annotation & versioning)
* OpenCV
* NumPy
* Matplotlib

---

## ðŸ“Š Model Training & Evaluation

* Custom dataset built from **150+ real-world images**
* Dataset annotated and versioned using Roboflow
* Model trained using Ultralytics YOLOv8 for **40 epochs**
* Evaluation metrics:

  * **mAP@50:** ~68%
  * **mAP@50â€“95:** ~58%
* Per-class precision, recall, and confusion matrix analysis performed during validation

---

## âš¡ On-Device Performance

**Tested on OnePlus Nord CE4 Lite**

* Inference latency: **~150â€“220 ms**
* Throughput: **~4â€“7 FPS**
* Hardware delegation: GPU â†’ NNAPI â†’ CPU fallback
* Model format: FP16 TensorFlow Lite

Performance metrics were measured using live CameraX input with real-time logging of inference latency and FPS.

---

## ðŸ“± Android Application Features

* Live camera feed powered by CameraX
* Real-time bounding box rendering
* FPS and inference latency logging (Logcat)
* Automatic hardware delegate selection
* Fully offline inference with no network dependency

---

## ðŸ§© Key Engineering Challenges Addressed

* Resolved **TensorFlow Lite output tensor mismatch** by re-exporting the YOLOv8 FP16 model with consistent class configuration
* Implemented **class-aware Non-Max Suppression (NMS)** to eliminate duplicate detections
* Integrated GPU delegate with NNAPI fallback for robust hardware acceleration
* Validated model performance using **live real-world detection**, not just offline datasets

---

## ðŸ”’ Privacy & Design Philosophy

* No internet connectivity required
* No image uploads or cloud inference
* Designed for edge deployment and privacy-preserving AI

---

## ðŸ“Œ Highlights

* End-to-end ML + Android deployment pipeline
* Hardware-accelerated on-device inference
* Real-device benchmarking and validation
* Clean, modular, and production-style project structure

---

## ðŸ‘¤ Author

**Naveen Ganesh**

---

> This project demonstrates practical experience in deploying modern deep learning models to mobile devices, with a strong focus on performance optimization, reliability, and real-world usability.
